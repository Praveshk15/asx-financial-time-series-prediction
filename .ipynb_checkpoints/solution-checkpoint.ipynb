{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Research Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this test is to give you a feel for the analysis of financial time series, and for us assess your ability in programming, machine learning, and statistical modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided data set contains ASX stock prices from Jan 2015 to June 2018. Each csv file contains end of day (EOD) data in the following format: Ticker, Date, Open, High, Low, Close, and Volume.\n",
    "\n",
    "The first task is converting the EOD data into five seperate time series data frames; one each for Open, High, Low Close and Volume. In each data frame, rows should be indexed by date, and columns by ticker.\n",
    "\n",
    "First, let's read the data from all the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# get list of file names from directory\n",
    "directory = \"./ASX-2015-2018/ASX-2015-2018/\"\n",
    "files = glob.glob(directory + '[0-9]*.txt')\n",
    "\n",
    "# generate list of dataframes from each file (or date) respectively\n",
    "cl_name = [\"ticker\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "dfs = [pd.read_csv(file, \n",
    "                   sep=\",\", \n",
    "                   names = cl_name, \n",
    "                   header = None, \n",
    "                   parse_dates = [\"date\"], \n",
    "                   index_col = \"date\") \n",
    "       for file in files]\n",
    "\n",
    "# concatenate the dataframes into one temporary dataframe\n",
    "df_master = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first understand how many tickers and observations (days) are there in total based on the concatenated dataframe `df_master`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2773 tickers with obervations over 883 days.\n"
     ]
    }
   ],
   "source": [
    "# number of tickers in dataframe\n",
    "print(\"There are {} tickers with obervations over {} days.\".format(df_master.ticker.unique().size, df_master.index.unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build dataframe for open, high, low, close, and volume as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pivot function, for each ticker values, individual dataframes for open, high, low, close, and volume can be built\n",
    "df_open = df_master[[\"ticker\", \"open\"]].pivot(columns = \"ticker\", values = \"open\")\n",
    "df_high = df_master[[\"ticker\", \"high\"]].pivot(columns = \"ticker\", values = \"high\")\n",
    "df_low = df_master[[\"ticker\", \"low\"]].pivot(columns = \"ticker\", values = \"low\")\n",
    "df_close = df_master[[\"ticker\", \"close\"]].pivot(columns = \"ticker\", values = \"close\")\n",
    "df_volume = df_master[[\"ticker\", \"volume\"]].pivot(columns = \"ticker\", values = \"volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the close price dataframe (head) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>1AD</th>\n",
       "      <th>1AG</th>\n",
       "      <th>1AL</th>\n",
       "      <th>1PG</th>\n",
       "      <th>1ST</th>\n",
       "      <th>3DM</th>\n",
       "      <th>3DP</th>\n",
       "      <th>3PL</th>\n",
       "      <th>4CE</th>\n",
       "      <th>4DS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNO</th>\n",
       "      <th>ZNT</th>\n",
       "      <th>ZNZ</th>\n",
       "      <th>ZOZI</th>\n",
       "      <th>ZRL</th>\n",
       "      <th>ZTA</th>\n",
       "      <th>ZUSD</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>ZYL</th>\n",
       "      <th>ZYUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker      1AD  1AG  1AL    1PG  1ST  3DM  3DP   3PL  4CE  4DS  ...   ZNO  \\\n",
       "date                                                             ...         \n",
       "2015-01-02  NaN  NaN  NaN  1.215  NaN  NaN  NaN  2.26  NaN  NaN  ...   NaN   \n",
       "2015-01-05  NaN  NaN  NaN  1.265  NaN  NaN  NaN  2.07  NaN  NaN  ...   NaN   \n",
       "2015-01-06  NaN  NaN  NaN  1.245  NaN  NaN  NaN  2.08  NaN  NaN  ...   NaN   \n",
       "2015-01-07  NaN  NaN  NaN  1.250  NaN  NaN  NaN  2.05  NaN  NaN  ...   NaN   \n",
       "2015-01-08  NaN  NaN  NaN  1.255  NaN  NaN  NaN  2.08  NaN  NaN  ...   NaN   \n",
       "\n",
       "ticker      ZNT   ZNZ  ZOZI    ZRL    ZTA  ZUSD  ZYB  ZYL  ZYUS  \n",
       "date                                                             \n",
       "2015-01-02  NaN   NaN   NaN  0.067    NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-05  NaN  4.40   NaN  0.070    NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-06  NaN  4.39   NaN    NaN    NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-07  NaN   NaN   NaN    NaN  0.003   NaN  NaN  NaN   NaN  \n",
       "2015-01-08  NaN   NaN   NaN    NaN    NaN   NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a dataframe containing the future close returns at time $t$, denoted as $r_{t,t+1}$, as defined by:\n",
    "\n",
    "$$r_{t,t+1}=\\frac{P^{c}_{t+1}}{P^{c}_{t}}-1,$$\n",
    "\n",
    "where $P^c_t$ is the close price at time $t$. This will be the quantity-of-interest that will be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>1AD</th>\n",
       "      <th>1AG</th>\n",
       "      <th>1AL</th>\n",
       "      <th>1PG</th>\n",
       "      <th>1ST</th>\n",
       "      <th>3DM</th>\n",
       "      <th>3DP</th>\n",
       "      <th>3PL</th>\n",
       "      <th>4CE</th>\n",
       "      <th>4DS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNO</th>\n",
       "      <th>ZNT</th>\n",
       "      <th>ZNZ</th>\n",
       "      <th>ZOZI</th>\n",
       "      <th>ZRL</th>\n",
       "      <th>ZTA</th>\n",
       "      <th>ZUSD</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>ZYL</th>\n",
       "      <th>ZYUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker      1AD  1AG  1AL       1PG  1ST  3DM  3DP       3PL  4CE  4DS  ...   \\\n",
       "date                                                                    ...    \n",
       "2015-01-02  NaN  NaN  NaN  0.041152  NaN  NaN  NaN -0.084071  NaN  NaN  ...    \n",
       "2015-01-05  NaN  NaN  NaN -0.015810  NaN  NaN  NaN  0.004831  NaN  NaN  ...    \n",
       "2015-01-06  NaN  NaN  NaN  0.004016  NaN  NaN  NaN -0.014423  NaN  NaN  ...    \n",
       "2015-01-07  NaN  NaN  NaN  0.004000  NaN  NaN  NaN  0.014634  NaN  NaN  ...    \n",
       "2015-01-08  NaN  NaN  NaN  0.015936  NaN  NaN  NaN  0.096154  NaN  NaN  ...    \n",
       "\n",
       "ticker      ZNO  ZNT       ZNZ  ZOZI       ZRL  ZTA  ZUSD  ZYB  ZYL  ZYUS  \n",
       "date                                                                       \n",
       "2015-01-02  NaN  NaN       NaN   NaN  0.044776  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-05  NaN  NaN -0.002273   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-06  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-07  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-08  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "# to find the future close return of t+1, or the close return of next business day, and assign to the index of t\n",
    "df_ftr_rtn = (df_close.shift(-1) / df_close) - 1\n",
    "df_ftr_rtn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also create a data frame containing close returns for the day, which is calculated with respect to the close price of the previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>1AD</th>\n",
       "      <th>1AG</th>\n",
       "      <th>1AL</th>\n",
       "      <th>1PG</th>\n",
       "      <th>1ST</th>\n",
       "      <th>3DM</th>\n",
       "      <th>3DP</th>\n",
       "      <th>3PL</th>\n",
       "      <th>4CE</th>\n",
       "      <th>4DS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNO</th>\n",
       "      <th>ZNT</th>\n",
       "      <th>ZNZ</th>\n",
       "      <th>ZOZI</th>\n",
       "      <th>ZRL</th>\n",
       "      <th>ZTA</th>\n",
       "      <th>ZUSD</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>ZYL</th>\n",
       "      <th>ZYUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker      1AD  1AG  1AL       1PG  1ST  3DM  3DP       3PL  4CE  4DS  ...   \\\n",
       "date                                                                    ...    \n",
       "2015-01-02  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...    \n",
       "2015-01-05  NaN  NaN  NaN  0.041152  NaN  NaN  NaN -0.084071  NaN  NaN  ...    \n",
       "2015-01-06  NaN  NaN  NaN -0.015810  NaN  NaN  NaN  0.004831  NaN  NaN  ...    \n",
       "2015-01-07  NaN  NaN  NaN  0.004016  NaN  NaN  NaN -0.014423  NaN  NaN  ...    \n",
       "2015-01-08  NaN  NaN  NaN  0.004000  NaN  NaN  NaN  0.014634  NaN  NaN  ...    \n",
       "\n",
       "ticker      ZNO  ZNT       ZNZ  ZOZI       ZRL  ZTA  ZUSD  ZYB  ZYL  ZYUS  \n",
       "date                                                                       \n",
       "2015-01-02  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-05  NaN  NaN       NaN   NaN  0.044776  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-06  NaN  NaN -0.002273   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-07  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-08  NaN  NaN       NaN   NaN       NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the future close return of t based on t-1 close values and assign to the index of t\n",
    "df_rtn = (df_close / df_close.shift(1)) - 1\n",
    "df_rtn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame containing the ratios of $\\frac{High}{Low}$ for each ticker each day, in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>1AD</th>\n",
       "      <th>1AG</th>\n",
       "      <th>1AL</th>\n",
       "      <th>1PG</th>\n",
       "      <th>1ST</th>\n",
       "      <th>3DM</th>\n",
       "      <th>3DP</th>\n",
       "      <th>3PL</th>\n",
       "      <th>4CE</th>\n",
       "      <th>4DS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNO</th>\n",
       "      <th>ZNT</th>\n",
       "      <th>ZNZ</th>\n",
       "      <th>ZOZI</th>\n",
       "      <th>ZRL</th>\n",
       "      <th>ZTA</th>\n",
       "      <th>ZUSD</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>ZYL</th>\n",
       "      <th>ZYUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.068966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.061224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.022727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.041322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.044534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker      1AD  1AG  1AL       1PG  1ST  3DM  3DP       3PL  4CE  4DS  ...   \\\n",
       "date                                                                    ...    \n",
       "2015-01-02  NaN  NaN  NaN  1.068966  NaN  NaN  NaN  1.055300  NaN  NaN  ...    \n",
       "2015-01-05  NaN  NaN  NaN  1.061224  NaN  NaN  NaN  1.111111  NaN  NaN  ...    \n",
       "2015-01-06  NaN  NaN  NaN  1.041322  NaN  NaN  NaN  1.039604  NaN  NaN  ...    \n",
       "2015-01-07  NaN  NaN  NaN  1.041667  NaN  NaN  NaN  1.050000  NaN  NaN  ...    \n",
       "2015-01-08  NaN  NaN  NaN  1.044534  NaN  NaN  NaN  1.014493  NaN  NaN  ...    \n",
       "\n",
       "ticker      ZNO  ZNT       ZNZ  ZOZI  ZRL  ZTA  ZUSD  ZYB  ZYL  ZYUS  \n",
       "date                                                                  \n",
       "2015-01-02  NaN  NaN       NaN   NaN  1.0  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-05  NaN  NaN  1.022727   NaN  1.0  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-06  NaN  NaN  1.006865   NaN  NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "2015-01-07  NaN  NaN       NaN   NaN  NaN  1.0   NaN  NaN  NaN   NaN  \n",
       "2015-01-08  NaN  NaN       NaN   NaN  NaN  NaN   NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 1031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe wirh ratio of high/low for each ticker on each day\n",
    "df_hl = df_high / df_low\n",
    "df_hl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Coverage and Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be observed from the dataframe printed out in the previous section, not all the tickers have complete data. There are 2773 unique tickers and 883 obervations. Now let us first visualise the distribution of number of non-missing values using dataframe `df_close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# histogram of the number of non-missing values\n",
    "ax = df_close.notna().sum().hist(bins=20)\n",
    "plt.xlabel(\"Number of observations\")\n",
    "plt.ylabel(\"Frequency (tickers)\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above shows that there are about 600 tickers with the number of non-missing values higher than 800 out of 883 observations, or in other words, about 600 tickers contain less than about 10% non-missing values. In this study, let us use just the tickers with less than 5% missing values for simplicity sake; and then deal with the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 883 entries, 2015-01-02 to 2018-06-29\n",
      "Columns: 513 entries, 3PL to YOW\n",
      "dtypes: float64(513)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "# get the array of tickers with less than 5% missing values\n",
    "tickers_good = df_close.columns[(df_close.notna().sum() > 840).values]\n",
    "\n",
    "# Let's inspect the dataframe with just the chosen tickers\n",
    "df_close[tickers_good].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 513 tickers with less than 5% missing values out of 883 observations. Let us first filter the ticker that we are interested in for all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open = df_open[tickers_good] # open\n",
    "df_high = df_high[tickers_good] # high\n",
    "df_low = df_low[tickers_good] # low\n",
    "df_close = df_close[tickers_good] # close\n",
    "df_volume = df_volume[tickers_good] # volume\n",
    "df_ftr_rtn = df_ftr_rtn[tickers_good] # future return\n",
    "df_rtn = df_rtn[tickers_good] # return\n",
    "df_hl = df_hl[tickers_good] # high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of curiosity, let's first inspect the master dataframe `df_master` if that is clean and if any values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker    0\n",
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_master).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the clean master dataframe `df_master`, we can safely assume all missing values are caused by no trades recorded on that day. With this assumption the strategy to replace the missing values could be as follows: Volume set to 0 and open, high, low, and close values set to previous day's close value with the assumption that no trade occured on that day for that particular ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = df_close.fillna(method=\"ffill\") # close\n",
    "df_close = df_close.fillna(method=\"bfill\") # to handle the first row of close\n",
    "# df_volume = df_volume.applymap(lambda x: 0 if pd.isna(x) is True else x) # volume\n",
    "df_volume = df_volume.fillna(method=\"ffill\")\n",
    "df_volume = df_volume.fillna(method=\"bfill\")\n",
    "df_open = df_open.fillna(df_close) # open\n",
    "df_high = df_high.fillna(df_close) # high\n",
    "df_low = df_low.fillna(df_close) # low\n",
    "\n",
    "# calculate other dataframes\n",
    "df_ftr_rtn = (df_close.shift(-1) / df_close) - 1 # future return\n",
    "df_rtn = (df_close / df_close.shift(1)) - 1 # return\n",
    "df_hl = df_high / df_low # high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study, it would be a very time consuming to analyse all 513 tickers. To keep the study succinct, let's take 100 tickers of the total number by picking the tickers that have highest mean absolute correlation (from other values such as open, high, low, close, volume, daily return, and high/low) to future return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us rank the tickers in ascending order of average correlation\n",
    "df_corr_score = pd.DataFrame()\n",
    "\n",
    "# We also want to make sure we don't take into account composite indexes. They can be identified by 0 volume.\n",
    "comp_indexes = df_volume.columns[(df_volume.sum() == 0).values].values\n",
    "\n",
    "# Loops over every ticker\n",
    "for ticker in tickers_good:\n",
    "    if ticker in comp_indexes:\n",
    "        # skip compund indexes\n",
    "        pass\n",
    "    else:\n",
    "        df = pd.concat([df_open[ticker], \n",
    "                        df_high[ticker], \n",
    "                        df_low[ticker], \n",
    "                        df_close[ticker], \n",
    "                        df_volume[ticker], \n",
    "                        df_ftr_rtn[ticker], \n",
    "                        df_rtn[ticker], \n",
    "                        df_hl[ticker]], \n",
    "                       axis=1, \n",
    "                       keys=[\"open\", \"high\", \"low\", \"close\", \"volume\", \"future_return\", \"return\", \"high_low\"])\n",
    "        df_corr_score = df_corr_score.append({\"ticker\": ticker, \n",
    "                                              \"avg_corr\": df.corr().drop(\"future_return\", axis = 1).loc['future_return'].abs().mean()}, \n",
    "                                             ignore_index = True)\n",
    "\n",
    "# this will be the 20 tickers we will use in this study\n",
    "tickers_final = df_corr_score.sort_values(by = [\"avg_corr\"], ascending = False).iloc[:100][\"ticker\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now modify our dataframes again based on the 20 tickers that is of interest to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open = df_open[tickers_final] # open\n",
    "df_high = df_high[tickers_final] # high\n",
    "df_low = df_low[tickers_final] # low\n",
    "df_close = df_close[tickers_final] # close\n",
    "df_volume = df_volume[tickers_final] # volume\n",
    "df_ftr_rtn = df_ftr_rtn[tickers_final] # future return\n",
    "df_rtn = df_rtn[tickers_final] # return\n",
    "df_hl = df_hl[tickers_final] # high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to employ LSTM with technical indicators. As some technical indicators use volume, volumes with 0 values are gonna become outliers. Let's remove those entries now to keep the data clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_bool = ~(df_volume == 0.0).sum(axis=1).astype(bool)\n",
    "\n",
    "# df_close = df_close.loc[row_bool] # close\n",
    "# df_open = df_open.loc[row_bool] # open\n",
    "# df_high = df_high.loc[row_bool] # high\n",
    "# df_low = df_low.loc[row_bool] # low\n",
    "# df_volume = df_volume.loc[row_bool] # volume\n",
    "\n",
    "# # calculate other dataframes\n",
    "# df_ftr_rtn = (df_close.shift(-1) / df_close) - 1 # future return\n",
    "# df_rtn = (df_close / df_close.shift(1)) - 1 # return\n",
    "# df_hl = df_high / df_low # high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Additional Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into performing some EDA, let us look at some additional transformations, or in other words, feature engineering. In essence, we would want to engineer features such that they possess some level of predictive power that could indicate the future direction of the market. Statistically speaking, these features should generally have good correlation to the market movement.\n",
    "\n",
    "There are numerous such transformations in literature [1-5]. The work by Borovkova et al. [1] consolidates some of the key technical indicators which can be used for additional transformations. Typically, they can be categorised into four groups: (1) Momentum; (2) Trend; (3) Volume; and (4) Volatility. Some of the commonly used indicators are:\n",
    "\n",
    "    1. Momentum:\n",
    "        a. Money flow index \n",
    "        b. Relative strength index\n",
    "        c. Stochastic oscillator (%K)\n",
    "        d. Stochastic oscillator (%D)\n",
    "        e. William %R\n",
    "        f. Rate of change\n",
    "    2. Trend:\n",
    "        a. Exponential moving average\n",
    "        b. Moving average convergence-divergence\n",
    "        c. Commodity channel index\n",
    "        d. Ichimoku Indicator\n",
    "    3. Volume:\n",
    "        a. Accumulation/distribution index\n",
    "    4. Volatility:\n",
    "        a. Bollinger bands \n",
    "    \n",
    "\n",
    "Now, let us perform additional transformations. To keep this document succinct, the definition of these indicators-of-interest will be described, whereas information of the other indicators can be obtained from [1, 2]. All tranformations will be employing the open-source Python package [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Money flow index (MFI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Money flow index is calculated based on the price and volume to indicate the strength of money in and out from a particular ticker, or in other words, if a particular stock is overbought or oversold. Typically, when MFI of above 80 indicates overbought and oversold when it is below 20.\n",
    "\n",
    "The MFI can be calculated as follows:\n",
    "\n",
    "$$\\text{MFI} = 100 - \\frac{100}{1+\\text{MFR}}$$\n",
    "where\n",
    "$$\\text{MFR} = \\frac{\\text{Positive Money Flow}}{\\text{Negative Money Flow}}$$\n",
    "\n",
    "$$\\text{Money Flow} = \\left(\\frac{\\text{High} + \\text{Low} + \\text{Close}}{3}\\right)\\text{Volume}$$\n",
    "\n",
    "and MFR denotes money flow ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta # import package\n",
    "\n",
    "# mfi dataframe\n",
    "df_mfi = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate mfi\n",
    "    temp = ta.momentum.money_flow_index(high=df_high[ticker], \n",
    "                                      low=df_low[ticker], \n",
    "                                      close=df_close[ticker], \n",
    "                                      volume=df_volume[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_mfi = pd.concat([df_mfi, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_mfi.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential moving average (EMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exponential moving average is exponentially weighed moving average calculated by exponentially decreasing the weight of observations $x_i$ with respect to their distance from $x_t$ using weighted multiplier $\\alpha$. For example, $\\alpha = 0.1$ gets only 10% of the current value into EMA. Since only a small portion of the current value is taken, most of the old values are preserved. Essentially, EMA is defined as:\n",
    "\n",
    "$$\\text{EMA}(x_t, \\alpha) = \\alpha x_t + (1 âˆ’ \\alpha) \\text{EMA}(x_{tâˆ’1}, \\alpha).$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\alpha = \\frac{2}{N+1}$$\n",
    "\n",
    "where $N$ is number of days in a period. In this study, let us use $N = 10$ to be consistent with MFI, and hence $\\alpha = 0.13333$ using the close price of day $t$ as $x_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ema dataframe\n",
    "df_ema = df_close.apply(ta.trend.ema_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative strength index (RSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the MFI, the relative strength index is another momentum indicator, but uses the velocity and magnitude of price momevents and also to indicate whether a stock is overbought or oversold. The RSI can be simply calculated as follows:\n",
    "\n",
    "$$\\text{RSI} = 100 - \\frac{100}{1+\\text{RS}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\text{RS} = \\frac{\\text{Average of up closes}}{\\text{Average of down closes}}$$\n",
    "\n",
    "is the relative strength. For consistency, let us use $N = 10$ when calculating the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ema dataframe\n",
    "df_rsi = df_close.apply(ta.momentum.rsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic oscillator (SO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stochastic oscillator (or Stochastic %K) is a momentum indicator calculated using the highest high price over a period of time $N$, lowest low price over a period of time $N$, and the current close price. The calculation can be simply performed as:\n",
    "\n",
    "$$\\text{%K} = \\left(\\frac{\\text{Close} - \\text{Lowest Low}}{\\text{Highest High} - \\text{Lowest Low}} \\right)*100$$\n",
    "\n",
    "which gives the result in percentage.\n",
    "\n",
    "The fast stochastic indicator (Stochastic %D) is normally the 3-period moving average of %K. Both indicators will be calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoch_k and stoch_d dataframe\n",
    "df_stoch_k = pd.DataFrame()\n",
    "df_stoch_d = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate %k\n",
    "    temp = ta.momentum.stoch(high=df_high[ticker],\n",
    "                             low=df_low[ticker],\n",
    "                             close=df_close[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_stoch_k = pd.concat([df_stoch_k, temp], axis=1)\n",
    "    \n",
    "    # calculate %d\n",
    "    temp = ta.momentum.stoch_signal(high=df_high[ticker],\n",
    "                             low=df_low[ticker],\n",
    "                             close=df_close[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_stoch_d = pd.concat([df_stoch_d, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_stoch_k.columns = df_close.columns\n",
    "df_stoch_d.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving average convergence-divergence (MACD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average convergence-divergence is an indicator that shows the relationship between 12-period EMA and 26-period EMA. This index can be used to measure the trend-following momentum of a security. Accordingly, it is calculated as:\n",
    "\n",
    "$$\\text{MACD} = \\text{12-Period EMA} - \\text{26-Period EMA}$$\n",
    "\n",
    "where EMA is the exponential moving average, as defined and programmed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macd dataframe\n",
    "df_macd = df_close.apply(ta.trend.macd_diff, fillna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### William %R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "William's %R is another momentum indicator that ranges between -100 and 0 which shows the overbought and oversold of a stock price. For example, a reading above -20 is overbought and a reading below -80 is oversold. Typically, it is calculated over the period of last $N=14$ days.\n",
    "\n",
    "This indicator can be simply calculated as follows:\n",
    "\n",
    "$$\\text{%R} = \\frac{\\text{Highest High} - \\text{Close}}{\\text{Highest High} - \\text{Lowest Low}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "# william_r dataframe\n",
    "df_will_r = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate william_r\n",
    "    temp = ta.momentum.wr(high=df_high[ticker],\n",
    "                          low=df_low[ticker],\n",
    "                          close=df_close[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_will_r = pd.concat([df_will_r, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_will_r.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commodity Channel Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commodity channel index is another trend indicator, but the difference in this indicator is that it measures the difference between the current price and the historical average price. This indicator can be calculated as follows:\n",
    "\n",
    "$$\\text{CCI}=\\frac{1}{0.015}\\frac{\\text{Typical Price}-\\text{SMA}\\left( \\text{Typical Price}\\right)}{\\text{MD}\\left( \\text{Typical Price}\\right)}$$\n",
    "\n",
    "where $\\text{SMA}$ is the simple moving average and $\\text{MD}$ is the mead absolute deviation.\n",
    "\n",
    "When the CCI is above zero it indicates the price is above the historic average. When CCI is below zero, the price is below the historic average. Readings above 100 typically signals buy signal; and sell signal for reading below -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cci dataframe\n",
    "df_cci = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate cci\n",
    "    temp = ta.trend.cci(high=df_high[ticker],\n",
    "                        low=df_low[ticker],\n",
    "                        close=df_close[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_cci = pd.concat([df_cci, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_cci.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ichimoku Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ichimoku Cloud is a collection of technical indicators that show support and resistance levels, as well as momentum and trend direction. To keep the indicators simple, only the two important indicators from Ichimoku Cloud are used: leading spans A and B. More information on the Ichimoku indicator can be found in [6]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ichi_a and ichi_b dataframe\n",
    "df_ichi_a = pd.DataFrame()\n",
    "df_ichi_b = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate ichi_a\n",
    "    temp = ta.trend.ichimoku_a(high=df_high[ticker],\n",
    "                               low=df_low[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_ichi_a = pd.concat([df_ichi_a, temp], axis=1)\n",
    "    \n",
    "    # calculate ichi_b\n",
    "    temp = ta.trend.ichimoku_b(high=df_high[ticker],\n",
    "                               low=df_low[ticker])\n",
    "    # concatenate with main dataframe\n",
    "    df_ichi_b = pd.concat([df_ichi_b, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_ichi_a.columns = df_close.columns\n",
    "df_ichi_b.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accumulation/Distribution Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulation/distribution is a cummulative indicator that makes use of volume and price to determine if the stock is being accummulated of distributed. Typically, a rising A/D line helps confirm a rising price trend whereas a falling A/D line helps confirm a price downtrend.\n",
    "\n",
    "$$\\text{A/D} = \\text{Previous A/D} + { (\\text{Close} - \\text{Low}) - (\\text{High} - \\text{Close}) \\over \\text{High} - \\text{Low} }*\\text{Volume}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/D dataframe\n",
    "df_ad = pd.DataFrame()\n",
    "\n",
    "# loop over all tickers\n",
    "for ticker in df_close.columns:\n",
    "    # calculate cci\n",
    "    temp = ta.volume.acc_dist_index(high=df_high[ticker],\n",
    "                                    low=df_low[ticker],\n",
    "                                    close=df_close[ticker],\n",
    "                                    volume=df_volume[ticker]\n",
    "                                   )\n",
    "    # concatenate with main dataframe\n",
    "    df_ad = pd.concat([df_ad, temp], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df_ad.columns = df_close.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bollinger Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bollinger bands are two lines that are two standard deviations away from the EMA. It is a volatility indicator. Here, it will be presented in terms of percentage as:\n",
    "\n",
    "$$\\text{BB} = \\frac{\\text{Close}-\\text{Lower Band}}{\\text{Higher Band} - \\text{Lower Band}}$$\n",
    "\n",
    "Typically, value of above 0.8 gives sell signal; and buy signal for value below 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower band\n",
    "up = df_close.apply(ta.volatility.bollinger_hband)\n",
    "down = df_close.apply(ta.volatility.bollinger_lband)\n",
    "    \n",
    "# Calculate percentage and return and store as bbp\n",
    "df_bbp = (df_close - down) / (up - down)\n",
    "df_bb_diff = up - down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all dataframes into test, training, and evaluation sets\n",
    "#\n",
    "# datetime range: 2015-01-02 to 2018-06-29\n",
    "# train: 2015-02-01 to 2017-06-30\n",
    "# validation: 2017-07-01 to 2017-12-31\n",
    "# test: 2018-01-01 to 2018-06-29\n",
    "#\n",
    "\n",
    "# Create target dataframe\n",
    "df_target = (df_ftr_rtn > 0).astype(int)\n",
    "\n",
    "\n",
    "# list all the dataframes of interest\n",
    "dfois = [df_open, df_high, df_low, df_close, df_volume, df_ftr_rtn, df_rtn, df_hl, df_target]\n",
    "# dfois = [df_open, df_high, df_low, df_close,df_volume, df_ftr_rtn, df_rtn, df_hl,\n",
    "#          df_mfi, df_ema, df_rsi, df_stoch_k, df_stoch_d, df_macd, df_will_r, df_cci,\n",
    "#          df_ichi_a, df_ichi_b, df_ad, df_bbp, df_bb_diff, df_target]\n",
    "# dfois = [df_rtn, df_hl,df_mfi, df_ema, df_rsi, df_stoch_k, df_stoch_d, df_macd, \n",
    "#          df_will_r, df_cci, df_ichi_a, df_ichi_b, df_ad, df_bb_diff, df_target]\n",
    "# dfois = [df_rtn, df_hl, df_ema, df_rsi, df_stoch_k, df_stoch_d, df_macd, \n",
    "#          df_will_r, df_cci, df_ichi_a, df_ichi_b, df_bbp, df_bb_diff, df_target]\n",
    "\n",
    "# list all the dataframes of interest in string\n",
    "dfois_str = ['df_open', 'df_high', 'df_low', 'df_close','df_volume', 'df_ftr_rtn', 'df_rtn', 'df_hl', 'df_target']\n",
    "# dfois_str = ['df_open', 'df_high', 'df_low', 'df_close','df_volume', 'df_ftr_rtn', 'df_rtn', 'df_hl',\n",
    "#          'df_mfi', 'df_ema', 'df_rsi', 'df_stoch_k', 'df_stoch_d', 'df_macd', 'df_will_r', 'df_cci',\n",
    "#          'df_ichi_a', 'df_ichi_b', 'df_ad', 'df_bbp', 'df_bb_diff', 'df_target']\n",
    "# dfois_str = ['df_rtn', 'df_hl', 'df_mfi', 'df_ema', 'df_rsi', 'df_stoch_k', 'df_stoch_d', 'df_macd', \n",
    "#              'df_will_r', 'df_cci', 'df_ichi_a', 'df_ichi_b', 'df_ad', 'df_bb_diff', 'df_target']\n",
    "# dfois_str = ['df_rtn', 'df_hl', 'df_ema', 'df_rsi', 'df_stoch_k', 'df_stoch_d', 'df_macd', \n",
    "#              'df_will_r', 'df_cci', 'df_ichi_a', 'df_ichi_b', 'df_bbp', 'df_bb_diff', 'df_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dates prior to 2015-02-01\n",
    "[df.drop(df.iloc[df.index < '2015-02-01'].index, inplace=True) for df in dfois];\n",
    "[df.drop(df.iloc[df.index == '2018-06-29'].index, inplace=True) for df in dfois];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# perform normalisation for each dataframe between 0 and 1\n",
    "nomaliser = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "for i, df in enumerate(dfois[:-1]):\n",
    "    columns = df.columns\n",
    "    index = df.index\n",
    "    df = nomaliser.fit_transform(df)\n",
    "    dfois[i] = pd.DataFrame(df, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "dfois_train = []\n",
    "for df in dfois:\n",
    "    dfois_train.append(df.iloc[df.index < '2017-07-01'])\n",
    "\n",
    "# test set\n",
    "dfois_test = []\n",
    "for df in dfois:\n",
    "    dfois_test.append(df.iloc[df.index >= '2018-01-01'])\n",
    "\n",
    "# evaluation set\n",
    "dfois_eval = []\n",
    "for df in dfois:\n",
    "    dfois_eval.append(df.iloc[(df.index >= '2017-07-01') & (df.index < '2018-01-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise the data by fitting the train set\n",
    "for i, _ in enumerate(dfois[:-1]):\n",
    "    # Create the Scaler object\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    # Columns and indexes\n",
    "    columns = dfois_train[i].columns\n",
    "    index_train = dfois_train[i].index\n",
    "    index_test = dfois_test[i].index\n",
    "    index_eval = dfois_eval[i].index\n",
    "    \n",
    "    # Fit scale\n",
    "    scaler.fit(dfois_train[i])\n",
    "    \n",
    "    # Trasform\n",
    "    train_data = scaler.transform(dfois_train[i])\n",
    "    eval_data = scaler.transform(dfois_eval[i])\n",
    "    test_data = scaler.transform(dfois_test[i])\n",
    "    \n",
    "    # Replace list\n",
    "    dfois_train[i] = pd.DataFrame(train_data, columns=columns, index=index_train)\n",
    "    dfois_eval[i] = pd.DataFrame(eval_data, columns=columns, index=index_eval)\n",
    "    dfois_test[i] = pd.DataFrame(test_data, columns=columns, index=index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange sequential_data\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# look at the past 60 days\n",
    "SEQ_LEN = 60\n",
    "\n",
    "def sequence_data(df_list):\n",
    "    # this is a list that will CONTAIN the sequences\n",
    "    sequential_data = []\n",
    "\n",
    "    for ticker in df_close.columns:\n",
    "        # initialise dataframe\n",
    "        df_ticker = pd.DataFrame()\n",
    "\n",
    "        # concatenate the dataframes\n",
    "        for df in df_list:\n",
    "            df_ticker = pd.concat([df_ticker, df[ticker]], axis=1)\n",
    "\n",
    "        prev_days = deque(maxlen=SEQ_LEN)\n",
    "        for i in df_ticker.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "                \n",
    "        # shuffle\n",
    "        random.shuffle(sequential_data)\n",
    "\n",
    "    return sequential_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55200\n",
      "6900\n",
      "6400\n"
     ]
    }
   ],
   "source": [
    "# scale all data\n",
    "sequential_data_train = sequence_data(dfois_train)\n",
    "sequential_data_eval = sequence_data(dfois_eval)\n",
    "sequential_data_test = scale_data(dfois_test)\n",
    "\n",
    "# print the length\n",
    "print(len(sequential_data_train))\n",
    "print(len(sequential_data_eval))\n",
    "print(len(sequential_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance train and evaluation data\n",
    "def balance_data(sequential_data):\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform balancing by calling the function\n",
    "train_x, train_y = balance_data(sequential_data_train)\n",
    "validation_x, validation_y = balance_data(sequential_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Borovkova S, Tsiamas I. An ensemble of LSTM neural networks for high-frequency stock market classification. Journal of Forecasting. 2019;1â€“20. https://doi.org/10.1002/for.2585\n",
    "\n",
    "[2] Hegazy O, Soliman OS, Salam MA. A Machine Learning Model for Stock Market Prediction. International Journal of Computer Science and Telecommunications. 2013; 17-23. https://www.ijcst.org/Volume4/Issue12/p4_4_12.pdf\n",
    "\n",
    "[3] Vargas MR, dos-Anjos CEM, Bichara GLG ; Evsukoff AG. Deep Learning for Stock Market Prediction Using Technical Indicators and Financial News Articles. 2018; https://doi.org/10.1109/IJCNN.2018.8489208\n",
    "\n",
    "[4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
